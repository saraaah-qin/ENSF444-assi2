{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92778525",
      "metadata": {
        "id": "92778525"
      },
      "source": [
        "<font size=\"+3\"><b>Assignment 2: Linear Models and Validation Metrics</b></font>\n",
        "\n",
        "***\n",
        "* **Full Name** = Sarah Qin \n",
        "* **UCID** = 10156892\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "<font color='Blue'>In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.</font>\n",
        "\n",
        "You can use the Table of Content on the left side of this notebook to efficiently navigate within this documents.\n",
        "\n",
        "|                **Question**                | **Point** |\n",
        "|:------------------------------------------:|:---------:|\n",
        "|         **Part 1: Classification**         |           |\n",
        "|          Step 0: Import Libraries          |           |\n",
        "|             Step 1: Data Input             |     1     |\n",
        "|           Step 2: Data Processing          |    1.5    |\n",
        "| Step 3: Implement Machine Learning   Model |           |\n",
        "|           Step 4: Validate Model           |           |\n",
        "|          Step 5: Visualize Results         |     4     |\n",
        "|                  Questions                 |     4     |\n",
        "|             Process Description            |     4     |\n",
        "|           **Part 2: Regression**           |           |\n",
        "|             Step 1: Data Input             |     1     |\n",
        "|           Step 2: Data Processing          |    0.5    |\n",
        "| Step 3: Implement Machine Learning   Model |     1     |\n",
        "|            Step 4: Validate Mode           |     1     |\n",
        "|          Step 5: Visualize Results         |     1     |\n",
        "|                  Questions                 |     2     |\n",
        "|             Process Description            |     4     |\n",
        "|  **Part 3:   Observations/Interpretation** |   **3**   |\n",
        "|           **Part 4: Reflection**           |   **2**   |\n",
        "|                  **Total**                 |   **30**  |\n",
        "|                                            |           |\n",
        "|                  **Bonus**                 |           |\n",
        "|         **Part 5: Bonus Question**         |   **4**   |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "# **Part 1: Classification (14.5 marks total)**\n",
        "\n",
        "|                **Question**                | **Point** |\n",
        "|:------------------------------------------:|:---------:|\n",
        "|         **Part 1: Classification**         |           |\n",
        "|          Step 0: Import Libraries          |           |\n",
        "|             Step 1: Data Input             |     1     |\n",
        "|           Step 2: Data Processing          |    1.5    |\n",
        "| Step 3: Implement Machine Learning   Model |           |\n",
        "|           Step 4: Validate Model           |           |\n",
        "|          Step 5: Visualize Results         |     4     |\n",
        "|                  Questions                 |     4     |\n",
        "|             Process Description            |     4     |\n",
        "|                  **Total**                 |  **14.5** |\n",
        "\n",
        "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3c6fc8",
      "metadata": {
        "id": "7e3c6fc8"
      },
      "source": [
        "## **Step 0:** Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "33f86925",
      "metadata": {
        "id": "33f86925"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Sarah\\AppData\\Local\\Temp\\ipykernel_9496\\1662815981.py:2: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "## **Step 1:** Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
        "\n",
        "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "33583c67",
      "metadata": {
        "id": "33583c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "262200 4600\n",
            "(4600, 57) (4600,)\n",
            "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import spam dataset from yellowbrick library\n",
        "# TO DO: Print size and type of X and y\n",
        "import setuptools\n",
        "from yellowbrick.datasets.loaders import load_spam\n",
        "\n",
        "X, y = load_spam()\n",
        "print(X.size, y.size)\n",
        "print(X.shape, y.shape)\n",
        "print(type(X), type(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "## **Step 2:** Data Processing (1.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4e7204f5",
      "metadata": {
        "id": "4e7204f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Check if there are any missing values and fill them in if necessary\n",
        "\n",
        "print(X.isnull().values.any())\n",
        "# X.fillna(X.mean(), inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a489285a",
      "metadata": {
        "id": "a489285a"
      },
      "source": [
        "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f9bc4a23",
      "metadata": {
        "id": "f9bc4a23"
      },
      "outputs": [],
      "source": [
        "# TO DO: Create X_small and y_small\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_small, X_test, y_small, y_test = train_test_split(X, y, test_size=0.95, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model\n",
        "\n",
        "1. Import `LogisticRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Implement the machine learning model with three different datasets:\n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89f3d84",
      "metadata": {
        "id": "b89f3d84"
      },
      "source": [
        "## **Step 4:** Validate Model\n",
        "\n",
        "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352106a3",
      "metadata": {
        "id": "352106a3"
      },
      "source": [
        "## **Step 5:** Visualize Results (4 marks for steps 3-5)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sarah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data Size</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262200</td>\n",
              "      <td>0.931957</td>\n",
              "      <td>0.932037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9200</td>\n",
              "      <td>0.616304</td>\n",
              "      <td>0.615561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13110</td>\n",
              "      <td>0.943478</td>\n",
              "      <td>0.905492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Data Size  Train Accuracy  Validation Accuracy\n",
              "0     262200        0.931957             0.932037\n",
              "1       9200        0.616304             0.615561\n",
              "2      13110        0.943478             0.905492"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=2000, random_state=0)\n",
        "\n",
        "# Train the model and get the accuracy for the full dataset\n",
        "lr.fit(X, y)\n",
        "train_accuracy = lr.score(X, y)\n",
        "test_accuracy = lr.score(X_test, y_test)\n",
        "\n",
        "data = {'Data Size': [X.size],'Train Accuracy': [train_accuracy], 'Validation Accuracy': [test_accuracy]}\n",
        "\n",
        "# Train the model and get the accuracy for the first 2 columns of the dataset\n",
        "df_X = X.iloc[:, 0:2]\n",
        "lr.fit(df_X, y)\n",
        "X_test2 = X_test.iloc[:, 0:2]\n",
        "train_accuracy = lr.score(df_X, y)\n",
        "test_accuracy = lr.score(X_test2, y_test)\n",
        "data['Data Size'].append(df_X.size)\n",
        "data['Train Accuracy'].append(train_accuracy)\n",
        "data['Validation Accuracy'].append(test_accuracy)\n",
        "\n",
        "# Train the model and get the accuracy for X_small\n",
        "lr.fit(X_small, y_small)\n",
        "train_accuracy = lr.score(X_small, y_small)\n",
        "test_accuracy = lr.score(X_test, y_test)\n",
        "\n",
        "# print('Train Accuracy:', train_accuracy)\n",
        "# print('Test Accuracy:', test_accuracy)\n",
        "data['Data Size'].append(X_small.size)\n",
        "data['Train Accuracy'].append(train_accuracy)\n",
        "data['Validation Accuracy'].append(test_accuracy)\n",
        "\n",
        "results = pd.DataFrame(data)\n",
        "\n",
        "results\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4427d4f",
      "metadata": {
        "id": "d4427d4f"
      },
      "source": [
        "## **Questions (4 marks)**\n",
        "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
        "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
        "\n",
        "<font color='Green'><b>\n",
        "1. Validation accuracy is highest when all data were used, followed by data using two columns only, and the least being the small samples, with their respective accuracy score of 0.93, 0.91, and 0.62.\n",
        "1. In this case, a false positive would be when there is no spam, but it was detected that there is a spam, and a false negative would be there is a spam but it was deteced as no spam. False negative is worse because it is better to say there is something when there isn't supposed to have something than there is something, but it is saying there isn't.\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7559517a",
      "metadata": {
        "id": "7559517a"
      },
      "source": [
        "## **Process Description (4 marks)**\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code? \n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59fe687f",
      "metadata": {
        "id": "59fe687f"
      },
      "source": [
        "<font color='Green'><b>\n",
        "1. I got my source code from the sklearn documentations for the logistic regression model.\n",
        "1. I followed the steps as dscribed above becuase it does make sense. \n",
        "1. I used ChatGPT to explain the error I got when the test_accuracy gave a ValueError message. I copied the error message into ChatGPT and asked it to explain to me what the error meant. I did modify the code by removing the line of code because that is where the error was. \n",
        "1. Yes, I was having trouble witht the ValueError value, then I asked a friend who is also in the class to check my code and try to figure out where the problem was. I then found out the problem was not the model fitting, the problem was the testing score line of code. \n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4c78a8",
      "metadata": {
        "id": "fb4c78a8"
      },
      "source": [
        "# **Part 2: Regression (10.5 marks total)**\n",
        "\n",
        "| **Question**                               | **Point** |\n",
        "|--------------------------------------------|-----------|\n",
        "| **Part 2: Regression**                     |           |\n",
        "| Step 1: Data Input                         | 1         |\n",
        "| Step 2: Data Processing                    | 0.5       |\n",
        "| Step 3: Implement Machine Learning   Model | 1         |\n",
        "| Step 4: Validate Mode                      | 1         |\n",
        "| Step 5: Visualize Results                  | 1         |\n",
        "| Questions                                  | 2         |\n",
        "| Process Description                        | 4         |\n",
        "| **Total**                                  | **10.5**  |\n",
        "\n",
        "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ba83c5",
      "metadata": {
        "id": "b2ba83c5"
      },
      "source": [
        "## **Step 1:** Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6ff2e34f",
      "metadata": {
        "id": "6ff2e34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8240 1030\n",
            "(1030, 8) (1030,)\n",
            "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import spam dataset from yellowbrick library\n",
        "# TO DO: Print size and type of X and y\n",
        "\n",
        "from yellowbrick.datasets.loaders import load_concrete\n",
        "\n",
        "X, y = load_concrete()\n",
        "print(X.size, y.size)\n",
        "print(X.shape, y.shape)\n",
        "print(type(X), type(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5294cfa",
      "metadata": {
        "id": "c5294cfa"
      },
      "source": [
        "## **Step 2:** Data Processing (0.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "693c5fa3",
      "metadata": {
        "id": "693c5fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Check if there are any missing values and fill them in if necessary\n",
        "\n",
        "print(X.isnull().values.any())\n",
        "# X.fillna(X.mean(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc60489",
      "metadata": {
        "id": "1bc60489"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model (1 mark)\n",
        "\n",
        "1. Import `LinearRegression` from sklearn\n",
        "2. Instantiate model `LinearRegression()`.\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suiGuK-W1WnL",
      "metadata": {
        "id": "suiGuK-W1WnL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b5041945",
      "metadata": {
        "id": "b5041945"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "lr = LinearRegression().fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1de28482",
      "metadata": {
        "id": "1de28482"
      },
      "source": [
        "## **Step 4:** Validate Model (1 mark)\n",
        "\n",
        "Calculate the training and validation accuracy using mean squared error and R2 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "970c038b",
      "metadata": {
        "id": "970c038b"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "MSE_train = mean_squared_error(y_train, lr.predict(X_train))\n",
        "MSE_test = mean_squared_error(y_test, lr.predict(X_test))\n",
        "\n",
        "data = {'Training Accuracy': [MSE_train], 'Testing Accuracy': [MSE_test]}\n",
        "\n",
        "R2_train = r2_score(y_train, lr.predict(X_train))\n",
        "R2_test = r2_score(y_test, lr.predict(X_test))\n",
        "\n",
        "data['Training Accuracy'].append(R2_train)\n",
        "data['Testing Accuracy'].append(R2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54aa7795",
      "metadata": {
        "id": "54aa7795"
      },
      "source": [
        "## **Step 5:** Visualize Results (1 mark)\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "88d223f3",
      "metadata": {
        "id": "88d223f3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Accuracy</th>\n",
              "      <th>Testing Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MSE</th>\n",
              "      <td>111.358439</td>\n",
              "      <td>95.904136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R2</th>\n",
              "      <td>0.610823</td>\n",
              "      <td>0.623414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Training Accuracy  Testing Accuracy\n",
              "MSE         111.358439         95.904136\n",
              "R2            0.610823          0.623414"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "\n",
        "indexLabels = ['MSE', 'R2']\n",
        "results = pd.DataFrame(data, index=indexLabels)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70a42bda",
      "metadata": {
        "id": "70a42bda"
      },
      "source": [
        "## **Questions (2 marks)**\n",
        "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
        "\n",
        "\n",
        "<font color='Green'><b>\n",
        "No, because the mean square error is large although the R2 value is moderately decent. A large mean square error means there is more discrepancy between the scores.\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca0ff2f",
      "metadata": {
        "id": "2ca0ff2f"
      },
      "source": [
        "## **Process Description (4 marks)**\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfdb0880",
      "metadata": {
        "id": "dfdb0880"
      },
      "source": [
        "<font color='Green'><b>\n",
        "1. I got my source code from the sklearn documentations for the linear regression model.\n",
        "1. I followed the steps as dscribed above. \n",
        "1. I did not use generative AI becuase the procedure is very similar to the previous task, so I was able work through it without asking generative AI to explain the error to me. \n",
        "1. No as I answered it in the previous question. This tasks is similar to the logistic regression so I did not have much struggle. \n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72ac3eb",
      "metadata": {
        "id": "e72ac3eb"
      },
      "source": [
        "# **Part 3: Observations/Interpretation (3 marks)**\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "<font color='Green'><b>ADD YOUR FINDINGS HERE</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b84eed",
      "metadata": {
        "id": "40b84eed"
      },
      "source": [
        "# **Part 4: Reflection (2 marks)**\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "<font color='Green'><b>\n",
        "I like that I get to apply the lecture knowledge into the assignment and I can get a deeper understanding of the difference in regression models. What I do not like is that I am not sure whether the results are correct because I don't know what I am expecting. Like I said early, I do enjoy learning the regression models by hands-on practice, but it is confusing becuase the scikit-learn does not provide details of functions. \n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db951b3a",
      "metadata": {
        "id": "db951b3a"
      },
      "source": [
        "# **Part 5: Bonus Question (4 marks)**\n",
        "\n",
        "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
        "\n",
        "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "47623d44",
      "metadata": {
        "id": "47623d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge Regression\n",
            "                   Training Accuracy  Testing Accuracy\n",
            "Ridge alpha=0.001           0.610823          0.623414\n",
            "Ridge alpha=0.01            0.610823          0.623414\n",
            "Ridge alpha=1               0.610823          0.623415\n",
            "Ridge alpha=10              0.610823          0.623418\n",
            "Ridge alpha=100             0.610823          0.623453\n",
            "\n",
            "Lasso Regression\n",
            "                   Training Accuracy  Testing Accuracy\n",
            "Lasso alpha=0.001           0.610823          0.623416\n",
            "Lasso alpha=0.01            0.610823          0.623429\n",
            "Lasso alpha=1               0.610609          0.624669\n",
            "Lasso alpha=10              0.604314          0.626774\n",
            "Lasso alpha=100             0.467576          0.507413\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "# Ridge Regression\n",
        "from sklearn.linear_model import Ridge\n",
        "ridge = Ridge(alpha=0.001).fit(X_train, y_train)\n",
        "ridge2 = Ridge(alpha=0.01).fit(X_train, y_train)\n",
        "ridge3 = Ridge(alpha=1).fit(X_train, y_train)\n",
        "ridge4 = Ridge(alpha=10).fit(X_train, y_train)\n",
        "ridge5 = Ridge(alpha=100).fit(X_train, y_train)\n",
        "\n",
        "R2_test = r2_score(y_test, ridge.predict(X_test))\n",
        "R2_test2 = r2_score(y_test, ridge2.predict(X_test))\n",
        "R2_test3 = r2_score(y_test, ridge3.predict(X_test))\n",
        "R2_test4 = r2_score(y_test, ridge4.predict(X_test))\n",
        "R2_test5 = r2_score(y_test, ridge5.predict(X_test))\n",
        "\n",
        "R2_train = r2_score(y_train, ridge.predict(X_train))\n",
        "R2_train2 = r2_score(y_train, ridge2.predict(X_train))\n",
        "R2_train3 = r2_score(y_train, ridge3.predict(X_train))\n",
        "R2_train4 = r2_score(y_train, ridge4.predict(X_train))\n",
        "R2_train5 = r2_score(y_train, ridge5.predict(X_train))\n",
        "\n",
        "data = {'Training Accuracy': [R2_train, R2_train2, R2_train3, R2_train4, R2_train5], 'Testing Accuracy': [R2_test, R2_test2, R2_test3, R2_test4, R2_test5]}\n",
        "indexLabels = ['Ridge alpha=0.001', 'Ridge alpha=0.01', 'Ridge alpha=1', 'Ridge alpha=10', 'Ridge alpha=100']\n",
        "results = pd.DataFrame(data, index=indexLabels)\n",
        "print(\"Ridge Regression\")\n",
        "print(results)\n",
        "print()\n",
        "\n",
        "# Lasso Regression\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso(alpha=0.001).fit(X_train, y_train)\n",
        "lasso2 = Lasso(alpha=0.01).fit(X_train, y_train)\n",
        "lasso3 = Lasso(alpha=1).fit(X_train, y_train)\n",
        "lasso4 = Lasso(alpha=10).fit(X_train, y_train)\n",
        "lasso5 = Lasso(alpha=100).fit(X_train, y_train)\n",
        "\n",
        "R2_test = r2_score(y_test, lasso.predict(X_test))\n",
        "R2_test2 = r2_score(y_test, lasso2.predict(X_test))\n",
        "R2_test3 = r2_score(y_test, lasso3.predict(X_test))\n",
        "R2_test4 = r2_score(y_test, lasso4.predict(X_test))\n",
        "R2_test5 = r2_score(y_test, lasso5.predict(X_test))\n",
        "\n",
        "R2_train = r2_score(y_train, lasso.predict(X_train))\n",
        "R2_train2 = r2_score(y_train, lasso2.predict(X_train))\n",
        "R2_train3 = r2_score(y_train, lasso3.predict(X_train))\n",
        "R2_train4 = r2_score(y_train, lasso4.predict(X_train))\n",
        "R2_train5 = r2_score(y_train, lasso5.predict(X_train))\n",
        "\n",
        "data = {'Training Accuracy': [R2_train, R2_train2, R2_train3, R2_train4, R2_train5], 'Testing Accuracy': [R2_test, R2_test2, R2_test3, R2_test4, R2_test5]}\n",
        "indexLabels = ['Lasso alpha=0.001', 'Lasso alpha=0.01', 'Lasso alpha=1', 'Lasso alpha=10', 'Lasso alpha=100']\n",
        "results = pd.DataFrame(data, index=indexLabels)\n",
        "print(\"Lasso Regression\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b606236",
      "metadata": {
        "id": "1b606236"
      },
      "source": [
        "<font color='Green'><b>ADD YOUR ANSWER HERE</b></font>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
